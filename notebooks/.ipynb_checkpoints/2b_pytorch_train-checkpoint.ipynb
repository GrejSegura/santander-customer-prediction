{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a prediction model using Pytorch Deep Learning\n",
    "=======================================\n",
    "**Author:** `Grej Segura`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## clear GPU memory to optimize capacity\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\User\\Documents\\Data_Science_Projects\\santander-customer-prediction')\n",
    "\n",
    "# load the cleanData\n",
    "# load the cleanData\n",
    "data = pd.read_csv(r'.\\data\\trainFinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.5, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device to GPU if Gpu exists else use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data = data.rename(columns={'target': 'labels'})\n",
    "    summary = data.describe().transpose()\n",
    "    cols = data[summary[summary['max']>1].reset_index()['index'].tolist()].columns[1:]\n",
    "\n",
    "    # separate the labels/target variable\n",
    "    dataX = data.drop(['labels'], axis = 1)\n",
    "    dataY = data['labels']\n",
    "\n",
    "    # Create train and test dataset\n",
    "    X_train, x_test, Y_train, y_test = train_test_split(dataX, dataY, stratify=dataY)\n",
    "\n",
    "    gather_data = pd.DataFrame(columns = ['feature', 'mean', 'std'])\n",
    "#    for i in cols:\n",
    "#        ave = X_train[i].mean()\n",
    "#        std = X_train[i].std()\n",
    "#        appended = pd.DataFrame({'feature': i, 'mean': ave, 'std': std}, index = [0])\n",
    "#        gather_data = gather_data.append(appended, ignore_index=True)\n",
    "#        x_test[i] = (x_test[i]-ave)/std\n",
    "#        X_train[i] = (X_train[i]-ave)/std\n",
    "\n",
    "    # First, scale the Data - only those numerical/non-categorical\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    return X_train, x_test, Y_train, y_test, #gather_data\n",
    "\n",
    "X_train, x_test, Y_train, y_test = preprocess_data(data)\n",
    "#gather_data.to_csv(r'.\\data\\output\\mean_std_scaler.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gather_data.to_csv(r'.\\data\\output\\mean_std_scaler.csv', index=False)\n",
    "n_columns = len(data.columns)\n",
    "del data\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the data to tensor and load to cuda memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(X, Y, x_test, y_test):\n",
    "    # making sure the training will use gpu\n",
    "    torch.cuda.set_device(0)\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    # convert all dataset to cuda tensor to be able to use the GPU\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    X = np.array(X)\n",
    "    x_test = np.array(x_test)\n",
    "    Y = np.array(Y)\n",
    "    y_test = np.array(y_test)\n",
    "    X_train = torch.tensor(X, device=device).type(dtype)\n",
    "    x_test = torch.tensor(x_test, device=device).type(dtype)\n",
    "\n",
    "\n",
    "    Y_train = torch.tensor(Y, device=device).type(dtype)\n",
    "    y_test = torch.tensor(y_test, device=device).type(dtype)\n",
    "\n",
    "    Y_train = torch.unsqueeze(Y_train, 1)\n",
    "    y_test = torch.unsqueeze(y_test, 1)\n",
    "    return X_train, x_test, Y_train, y_test\n",
    "\n",
    "X_train, x_test, Y_train, y_test = convert_to_tensor(X_train, Y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7478\n",
      "67522\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train[Y_train==1]))\n",
    "print(len(Y_train[Y_train==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-5cf6ce2e2020>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-5cf6ce2e2020>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    self.relu1 = nn.ReLU()\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(n_columns-1, (533)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "                \n",
    "        self.fc2 = nn.Linear(533, 355)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(355, 236)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc4 = nn.Linear(236, 157)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.dout = nn.Dropout(0.2)                             \n",
    "        \n",
    "        self.fc5 = nn.Linear(157, 100)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc6 = nn.Linear(100, 70)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "                             \n",
    "        self.fc7 = nn.Linear(70, 45)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "                             \n",
    "        self.fc8 = nn.Linear(45, 30)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc9 = nn.Linear(30, 10)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "                             \n",
    "        self.out = nn.Linear(10, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout = self.dout(h1)\n",
    "        \n",
    "        a2 = self.fc2(dout)\n",
    "        h2 = self.prelu(a2)\n",
    "        dout = self.dout(h2)\n",
    "        \n",
    "        a3 = self.fc3(dout)\n",
    "        h3 = self.prelu(a3)\n",
    "        dout = self.dout(h3)\n",
    "        \n",
    "        a4 = self.fc4(dout)\n",
    "        h4 = self.prelu(a4)\n",
    "        dout = self.dout(h4)\n",
    "        \n",
    "        a5 = self.fc5(dout)\n",
    "        h5 = self.prelu(a5)\n",
    "        dout = self.dout(h5)\n",
    "        \n",
    "        a6 = self.fc6(dout)\n",
    "        h6 = self.prelu(a6)\n",
    "        dout = self.dout(h6)\n",
    "\n",
    "        a7 = self.fc7(dout)\n",
    "        h7 = self.prelu(a7)\n",
    "        dout = self.dout(h7)\n",
    "                             \n",
    "        a8 = self.fc8(dout)\n",
    "        h8 = self.prelu(a8)\n",
    "        dout = self.dout(h8)\n",
    "                             \n",
    "        a9 = self.fc9(dout)\n",
    "        h8 = self.prelu(a9)\n",
    "                             \n",
    "        a10 = self.out(h8)\n",
    "        \n",
    "        y = self.out_act(a10)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier().cuda()\n",
    "criterion = nn.BCELoss() ## loss function for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003) ## adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clear GPU memory to optimize capacity\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "e_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # forward pass\n",
    "    outputs = model.forward(X_train)\n",
    "\n",
    "    # calculate loss (MSE)\n",
    "    loss = criterion(outputs, Y_train)\n",
    "    e_losses.append(loss.data.detach())\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # perform one step in the oposite direction to the gradient (update weights)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # clear gradient values after weights are updated\n",
    "    optimizer.zero_grad()\n",
    "    torch.cuda.empty_cache()\n",
    "    if epoch % 50 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "plt.plot(e_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_data(x_test, y_test, model):\n",
    "    # switch to evaluation mode\n",
    "    model = model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model.forward(x_test).cpu().numpy()\n",
    "\n",
    "    y_pred = y_pred >= 0.5\n",
    "    y_pred = y_pred.astype(int)\n",
    "    y_test = y_test.cpu().numpy()\n",
    "    accuracy = metrics.accuracy_score(y_pred, y_test).astype(str)\n",
    "    print('\\n\\naccuracy is ' + accuracy)\n",
    "\n",
    "    precision = metrics.precision_score(y_test, y_pred).astype(str)\n",
    "    print('precision is ' + precision)\n",
    "    recall = metrics.recall_score(y_test, y_pred).astype(str)\n",
    "    print('recall is ' + recall)\n",
    "    auc = metrics.roc_auc_score(np.asarray(y_test), y_pred).astype(str)\n",
    "    print('auc is ' + auc)\n",
    "\n",
    "    f1 = 2*((precision.astype(np.float64)*recall.astype(np.float64))/(precision.astype(np.float64)+recall.astype(np.float64)))\n",
    "    print('f1-score is ' + f1.astype(str))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "y_pred_train = predict_new_data(X_train, Y_train, model)\n",
    "y_pred_test = predict_new_data(x_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the model\n",
    "torch.save(model.state_dict(), r'.\\models\\pytorch_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clear GPU memory to optimize capacity\n",
    "torch.cuda.empty_cache()\n",
    "del X_train, Y_train, x_test, y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''accuracy is 0.9198761904761905\n",
    "precision is 0.7797716150081566\n",
    "recall is 0.27389934103715025\n",
    "auc is 0.6326652710221242\n",
    "f1-score is 0.4053996748886848\n",
    "\n",
    "\n",
    "accuracy is 0.9119428571428572\n",
    "precision is 0.6574074074074074\n",
    "recall is 0.24412607449856732\n",
    "auc is 0.6150176548310038\n",
    "f1-score is 0.3560384454659423'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
