{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "random.seed(22)\n",
    "\n",
    "## set the directory\n",
    "os.chdir(r'C:\\Users\\User\\Documents\\Data_Science_Projects\\santander-customer-prediction')\n",
    "\n",
    "# load the cleanData\n",
    "data = pd.read_csv(r'.\\data\\trainFinal.csv')\n",
    "testdata = pd.read_csv(r'.\\data\\testFinal.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6',\n",
       "       'var_7', 'var_8',\n",
       "       ...\n",
       "       'var_198_quantile_20', 'var_199_quantile_20', 'sum_rows', 'median_rows',\n",
       "       'mean_rows', 'min_rows', 'max_rows', 'std_rows', 'skew_rows',\n",
       "       'kurt_rows'],\n",
       "      dtype='object', length=817)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(r'.\\data\\features.csv')\n",
    "feature_imp = features[features['0']>0]\n",
    "feature_selected = np.array(feature_imp['1'])\n",
    "testdata = testdata[feature_selected]\n",
    "\n",
    "feature_selected = np.append(feature_selected, 'target')\n",
    "data = data[feature_selected]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data = data.rename(columns={'target': 'labels'})\n",
    "\n",
    "    # separate the labels/target variable\n",
    "    dataX = data.drop(['labels'], axis = 1)\n",
    "    dataY = data['labels']\n",
    "    \n",
    "    # Create train and test dataset\n",
    "    X_train, x_test, Y_train, y_test = train_test_split(dataX, dataY, test_size = 0.4, random_state = 0)\n",
    "    \n",
    "    # First, scale the Data - only those numerical/non-categorical\n",
    "    return X_train, x_test, Y_train, y_test\n",
    "\n",
    "X_train, x_test, Y_train, y_test = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(X_train, Y_train, x_test, y_test, n_estimators=500, n_jobs=-1, learning_rate=0.01):\n",
    "    gbm = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "    \n",
    "    ada = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "    \n",
    "    etrees = ExtraTreesClassifier(n_estimators=n_estimators, n_jobs=n_jobs)\n",
    "    \n",
    "    bernoulli = BernoulliNB()\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, n_jobs=n_jobs)\n",
    "    \n",
    "    logit = LogisticRegression(n_jobs=n_jobs)\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    knn21 = KNeighborsClassifier(n_neighbors=21, n_jobs=n_jobs)\n",
    "    knn31 = KNeighborsClassifier(n_neighbors=31, n_jobs=n_jobs)\n",
    "    knn41 = KNeighborsClassifier(n_neighbors=41, n_jobs=n_jobs)    \n",
    "    knn51 = KNeighborsClassifier(n_neighbors=51, n_jobs=n_jobs)\n",
    "        \n",
    "    lgbm = lgb.LGBMClassifier(boosting_type='gbdt',  \n",
    "                         objective='binary', \n",
    "                         metric='auc',\n",
    "                         verbose= 1,\n",
    "                         sub_feature= 0.55,\n",
    "                         seed= 123,\n",
    "                         save_binary= True,\n",
    "                         reg_alpha= 0.1,\n",
    "                         num_leaves= 6,\n",
    "                         num_boost_round= 700,\n",
    "                         min_data= 25,\n",
    "                         max_depth= 12,\n",
    "                         max_bin= 63,\n",
    "                         learning_rate= 0.1,\n",
    "                         lambda_l2= 0.4,\n",
    "                         lambda_l1= 0.7,\n",
    "                         is_unbalance= True,\n",
    "                         feature_fraction_seed= 1234,\n",
    "                         drop_seed= 1234,\n",
    "                         data_random_seed= 1234,\n",
    "                         boost_from_average= False,\n",
    "                         bagging_seed= 1234,\n",
    "                         bagging_freq= 5,\n",
    "                         bagging_fraction= 0.55,\n",
    "                         n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    models = {'gbm':gbm, 'ada':ada, 'etrees':etrees, 'bernoulli':bernoulli, \n",
    "              'rf':rf, 'logit':logit, 'lda':lda, 'knn21':knn21, 'knn31':knn31,\n",
    "              'knn41':knn41, 'knn51':knn51, 'lgbm':lgbm}\n",
    "    predicted = pd.DataFrame()\n",
    "    columns = ['auc', 'accuracy', 'precision', 'recall']\n",
    "    measures = pd.DataFrame(index=list(models.keys()), columns=columns)\n",
    "    preds = pd.Series()\n",
    "    for key, value in models.items():\n",
    "        value.fit(X_train, Y_train)\n",
    "        predictions = value.predict_proba(x_test)\n",
    "        predicted['probapreds_'+key] = pd.Series(predictions[:,1])\n",
    "        predicted.loc[predicted['probapreds_'+key]>=.5, 'preds_'+key] = 1\n",
    "        predicted.loc[predicted['probapreds_'+key]<.5, 'preds_'+key] = 0\n",
    "        measures[key, 'auc'] = metrics.roc_auc_score(np.asarray(y_test), np.asarray(predicted['preds_'+key])).astype(str)\n",
    "        measures[key, 'accuracy'] = metrics.accuracy_score(predicted['preds_'+key], y_test)\n",
    "        measures[key, 'precision'] = metrics.precision_score(y_test, predicted['preds_'+key])\n",
    "        measures[key, 'recall'] = metrics.recall_score(y_test, predicted['preds_'+key])\n",
    "        model_name = key+'.sav'\n",
    "        pickle.dump(value, open(r'.\\models\\model'+model_name, 'wb'))\n",
    "    predicted['y_test'] = y_test.reset_index().drop('index', axis=1)\n",
    "\n",
    "    return predicted, measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mr_gr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mr_gr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mr_gr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mr_gr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mr_gr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1297: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\mr_gr\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\mr_gr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mr_gr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predicted, measures = train_ensemble(X_train, Y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_data = predicted[['probapreds_gbm', 'probapreds_ada', 'probapreds_etrees', 'probapreds_bernoulli', \n",
    "                       'probapreds_rf', 'probapreds_logit', 'probapreds_lda', 'probapreds_knn', 'probapreds_lgbm', 'y_test']]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data = data.rename(columns={'y_test': 'labels'})\n",
    "\n",
    "    # separate the labels/target variable\n",
    "    dataX = data.drop(['labels'], axis = 1)\n",
    "    dataY = data['labels']\n",
    "    \n",
    "    # Create train and test dataset\n",
    "    X_train, x_test, Y_train, y_test = train_test_split(dataX, dataY, test_size = 0.3, random_state = 0)\n",
    "    \n",
    "    # First, scale the Data - only those numerical/non-categorical\n",
    "    return X_train, x_test, Y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pX_train, px_test, pY_train, py_test = preprocess_data(preds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train lgb classifier\n",
    "\n",
    "def train_model(X_train, Y_train):\n",
    "    model = lgb.LGBMClassifier(boosting_type='gbdt',  objective='binary', metric='auc',\n",
    "                                 verbose= 1,\n",
    "                                 sub_feature= 0.55,\n",
    "                                 seed= 123,\n",
    "                                 save_binary= True,\n",
    "                                 reg_alpha= 0.1,\n",
    "                                 num_leaves= 6,\n",
    "                                 num_boost_round= 700,\n",
    "                                 min_data= 25,\n",
    "                                 max_depth= 12,\n",
    "                                 max_bin= 63,\n",
    "                                 learning_rate= 0.1,\n",
    "                                 lambda_l2= 0.4,\n",
    "                                 lambda_l1= 0.7,\n",
    "                                 is_unbalance= True,\n",
    "                                 feature_fraction_seed= 1234,\n",
    "                                 drop_seed= 1234,\n",
    "                                 data_random_seed= 1234,\n",
    "                                 boost_from_average= False,\n",
    "                                 bagging_seed= 1234,\n",
    "                                 bagging_freq= 5,\n",
    "                                 bagging_fraction= 0.55)\n",
    "    #params['learning_rate'] = 0.1\n",
    "    #params['sub_feature'] = 0.6\n",
    "    #params['num_leaves'] = 14\n",
    "    #params['min_data'] = 20\n",
    "    #params['lambda_l1'] = 0.4\n",
    "    #params['lambda_l2'] = 0\n",
    "    #params['reg_alpha'] = 0\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    return model\n",
    "\n",
    "def predict_data(X, Y, data_type):\n",
    "    ## predicting test data\n",
    "    y_pred = model.predict(X)\n",
    "    for i in range(len(X)):\n",
    "        if y_pred[i]>=.5:       # setting threshold to .5\n",
    "           y_pred[i]=1\n",
    "        else:  \n",
    "           y_pred[i]=0\n",
    "\n",
    "    #print accuracy_score(y_test, predicted) for test data\n",
    "    accuracy = metrics.accuracy_score(y_pred, Y)\n",
    "    print('\\n\\n\\nThe following are metrices for ', data_type, ' data')\n",
    "    print('\\nACCURACY is ' + accuracy.astype(str))\n",
    "    preds = pd.DataFrame({'true': Y, 'predicted': y_pred})\n",
    "    confusion = pd.crosstab(preds['predicted'], preds['true'])\n",
    "    print('\\n CONFUSION MATRIX:\\n', confusion)\n",
    "    precision = metrics.precision_score(Y, y_pred)\n",
    "    print('\\n', data_type ,'DATA PRECISION ' + precision.astype(str))\n",
    "    recall = metrics.recall_score(Y, y_pred)\n",
    "    print('\\n', data_type ,'DATA RECALL ' + recall.astype(str))\n",
    "    auc = metrics.roc_auc_score(np.asarray(Y), y_pred).astype(str)\n",
    "    print('\\n', data_type ,'DATA AUC ' + auc.astype(str))\n",
    "    return y_pred\n",
    "\n",
    "model = train_model(pX_train, pY_train)\n",
    "preds_train = predict_data(pX_train, pY_train, data_type='TRAIN')\n",
    "preds_test = predict_data(px_test, py_test, data_type='TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(r'.\\models\\lightGBMmodelSTACKED.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
